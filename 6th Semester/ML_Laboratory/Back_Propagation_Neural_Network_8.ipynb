{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamathVaishnavi/Machine_Learning/blob/main/Back_Propagation_Neural_Network_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = ':https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F18285%2F23917%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240523%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240523T060953Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6e53706328eaa9af32dbb69f39b0df2ad128dc64dc2c4b151cb910bd6ab0d27f8d97b7df1c0475a75c458257b6523854a10555138d665823a7274a1978b249f180f48be23d80de109f11c8ed3ff600e8f41c4113a61361d46760f0f781612f72f50c4f7951bbfea9cd7cd0f91ae7d8532e6279f993b5345672ae92d3e46810de9f62e0c785991d5a0ad12a302a67fcbdf998ea02e80ff8cb723611e2abd76ad7e1e592ca5a6cb96154ba6f04b3252cc9fc1c8b39a535bc95c01004590b5fa9afcbd3567a74cb5ad243bc4fad9123776bf77ac8f5e8eba4d1a9e603d304553cf00de7c8959720d27875298e98357d89c1eb8fadc827d3e8871de90e1bfe4c7081'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "yId_Wdl3EggI",
        "outputId": "0240300f-ff06-4877-eda0-6e40b3e1fd5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading , 2350669 bytes compressed\n",
            "[==================================================] 2350669 bytes downloaded\n",
            "Downloaded and uncompressed: \n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "collapsed": true,
        "trusted": false,
        "id": "db9Nd--KEggJ",
        "outputId": "651cac6d-e675-4a6d-87e1-4141ee5e03ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "db = np.loadtxt(\"../input/duke-breast-cancer.txt\")\n",
        "print(\"Database raw shape (%s,%s)\" % np.shape(db))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database raw shape (86,7130)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "762d37c4dae44319c9d2422e169d7ea0f33572a9",
        "_cell_guid": "24bea183-2074-4d53-a47a-cf05bb5ec7ed",
        "collapsed": true,
        "trusted": false,
        "id": "tEtv7hpREggJ",
        "outputId": "0133d5c4-85e2-4a0b-87cc-46e07fd01b5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.shuffle(db)\n",
        "y = db[:, 0]\n",
        "x = np.delete(db, [0], axis=1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
        "print(np.shape(x_train),np.shape(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(77, 7129) (9, 7129)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c6e92169cd8d40cfbd6535d89ef9d568ec7f080a",
        "_cell_guid": "c56476bc-9ed6-4f59-adcc-05c1d7efffe8",
        "collapsed": true,
        "trusted": false,
        "id": "s9i_vFV5EggK"
      },
      "cell_type": "code",
      "source": [
        "hidden_layer = np.zeros(72)\n",
        "weights = np.random.random((len(x[0]), 72))\n",
        "output_layer = np.zeros(2)\n",
        "hidden_weights = np.random.random((72, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a9363b0d1930d5ab7bf109087c44f9f1f5378e04",
        "_cell_guid": "64eef7a8-6c64-41c9-857b-8719e740acb9",
        "collapsed": true,
        "trusted": false,
        "id": "bvK9wYz0EggK"
      },
      "cell_type": "code",
      "source": [
        "def sum_function(weights, index_locked_col, x):\n",
        "    result = 0\n",
        "    for i in range(0, len(x)):\n",
        "        result += x[i] * weights[i][index_locked_col]\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4d8da27a9d20a0d9e22ccbc7f2e97a2ad1ce3d8d",
        "_cell_guid": "6c9963c8-0c5b-4b5d-8254-940017be5147",
        "collapsed": true,
        "trusted": false,
        "id": "rO1ZmEH4EggK"
      },
      "cell_type": "code",
      "source": [
        "def activate_layer(layer, weights, x):\n",
        "    for i in range(0, len(layer)):\n",
        "        layer[i] = 1.7159 * np.tanh(2.0 * sum_function(weights, i, x) / 3.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cd1e82c77d052992d5b8bfe9ea4793c7dae9fa82",
        "_cell_guid": "c33b200b-07e1-475a-9310-4b6486f36f46",
        "collapsed": true,
        "trusted": false,
        "id": "vKFFKxoBEggK"
      },
      "cell_type": "code",
      "source": [
        "def soft_max(layer):\n",
        "    soft_max_output_layer = np.zeros(len(layer))\n",
        "    for i in range(0, len(layer)):\n",
        "        denominator = 0\n",
        "        for j in range(0, len(layer)):\n",
        "            denominator += np.exp(layer[j] - np.max(layer))\n",
        "        soft_max_output_layer[i] = np.exp(layer[i] - np.max(layer)) / denominator\n",
        "    return soft_max_output_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a2d58312392a090b6f9c07b4c251bfae866aaefa",
        "_cell_guid": "8ee9f8b5-35a4-4a20-85b6-e13fc2c16db8",
        "collapsed": true,
        "trusted": false,
        "id": "OvwT5U94EggK"
      },
      "cell_type": "code",
      "source": [
        "def recalculate_weights(learning_rate, weights, gradient, activation):\n",
        "    for i in range(0, len(weights)):\n",
        "        for j in range(0, len(weights[i])):\n",
        "            weights[i][j] = (learning_rate * gradient[j] * activation[i]) + weights[i][j]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bf147c36b5709607dad90ab78749a77dea18f0d6",
        "_cell_guid": "886bcb3a-4b24-4d2c-bb93-a932a0e5e5bf",
        "collapsed": true,
        "trusted": false,
        "id": "2oQ31OoWEggK"
      },
      "cell_type": "code",
      "source": [
        "def back_propagation(hidden_layer, output_layer, one_hot_encoding, learning_rate, x):\n",
        "    output_derivative = np.zeros(2)\n",
        "    output_gradient = np.zeros(2)\n",
        "    for i in range(0, len(output_layer)):\n",
        "        output_derivative[i] = (1.0 - output_layer[i]) * output_layer[i]\n",
        "    for i in range(0, len(output_layer)):\n",
        "        output_gradient[i] = output_derivative[i] * (one_hot_encoding[i] - output_layer[i])\n",
        "    hidden_derivative = np.zeros(72)\n",
        "    hidden_gradient = np.zeros(72)\n",
        "    for i in range(0, len(hidden_layer)):\n",
        "        hidden_derivative[i] = (1.0 - hidden_layer[i]) * (1.0 + hidden_layer[i])\n",
        "    for i in range(0, len(hidden_layer)):\n",
        "        sum_ = 0\n",
        "        for j in range(0, len(output_gradient)):\n",
        "            sum_ += output_gradient[j] * hidden_weights[i][j]\n",
        "        hidden_gradient[i] = sum_ * hidden_derivative[i]\n",
        "    recalculate_weights(learning_rate, hidden_weights, output_gradient, hidden_layer)\n",
        "    recalculate_weights(learning_rate, weights, hidden_gradient, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "842e987aa6eeab97f21fceb01c49d1465983e9cd",
        "_cell_guid": "9e2dbc9d-0f08-4c0b-94d7-31a4b90dc46c",
        "_kg_hide-input": false,
        "collapsed": true,
        "trusted": false,
        "id": "qZXsnDNvEggL",
        "outputId": "32554ee0-45a5-4324-e39f-d45606e66d63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "one_hot_encoding = np.zeros((2,2))\n",
        "for i in range(0, len(one_hot_encoding)):\n",
        "    one_hot_encoding[i][i] = 1\n",
        "training_correct_answers = 0\n",
        "for i in range(0, len(x_train)):\n",
        "    activate_layer(hidden_layer, weights, x_train[i])\n",
        "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
        "    output_layer = soft_max(output_layer)\n",
        "    training_correct_answers += 1 if y_train[i] == np.argmax(output_layer) else 0\n",
        "    back_propagation(hidden_layer, output_layer, one_hot_encoding[int(y_train[i])], -1, x_train[i])\n",
        "print(\"MLP Correct answers while learning: %s / %s (Accuracy = %s) on %s database.\" % (training_correct_answers, len(x_train),\n",
        "                                                                                       training_correct_answers/len(x_train),\"Duke breast cancer\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Correct answers while learning: 51 / 77 (Accuracy = 0.6623376623376623) on Duke breast cancer database.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_kg_hide-output": false,
        "_uuid": "d054f30b2e1514d48825906f72a667ae139dddda",
        "_cell_guid": "3e97419b-e5b8-4751-b1aa-b92adbdb7883",
        "collapsed": true,
        "trusted": false,
        "id": "hx2PQRdkEggL",
        "outputId": "ea186438-1fce-482e-85ab-cead61a60b3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "testing_correct_answers = 0\n",
        "for i in range(0, len(x_test)):\n",
        "    activate_layer(hidden_layer, weights, x_test[i])\n",
        "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
        "    output_layer = soft_max(output_layer)\n",
        "    testing_correct_answers += 1 if y_test[i] == np.argmax(output_layer) else 0\n",
        "print(\"MLP Correct answers while testing: %s / %s (Accuracy = %s) on %s database\" % (testing_correct_answers, len(x_test),\n",
        "                                                                                     testing_correct_answers/len(x_test), \"Duke breast cancer\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Correct answers while testing: 8 / 9 (Accuracy = 0.8888888888888888) on Duke breast cancer database\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-jUwBiIFVjg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}